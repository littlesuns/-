# 操作系统
---
## 进程和线程
### 进程
进程是具有一定功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源调度和分配的一个独立单位。
进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。
### 线程
线程是进程的实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。
一个进程可以有多个线程，它们共享进程资源，多个线程也可以并发执行。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

### 进程和线程的区别
* 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
* 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
* 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
* 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。
* 系统安全性

多进程程序更为健壮。多线程一个程序死掉之后，整个进程会崩溃。而多进程相互之间的影响比较小。

### 协程
协程可以理解为是一种轻量级的线程。一个线程可以拥有多个协程。协程不是被操作系统内核锁管理，而完全是由程序所控制，在用户态下执行。不需要像线程一样进行切换。

协程是指在一个函数运行到出现某种情况时暂停执行转而执行另一个函数。协程是单线执行的，没有多线程的开销，同时也没有多线程中的共享资源问题，不需要锁来保证安全。但也没有了多线程对多处理器资源的利用率优势，不过这个缺点可以用多进程的方式弥补。

和回调函数不同的是，回调的本质是函数调用，在运行时确定需要调用的函数。协程的重点是执行过程中的暂停执行，与多线程的切换相似，但没有多线程切换时的开销。

## 进程切换
### 用户空间 内核空间
对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2^32）。

操作系统将虚拟空间划分为两部分：
* 内核空间（Linux 最高的1G字节，从虚拟地址0xC0000000到0xFFFFFFFF）
* 用户空间（Linux 最低的3G字节，从虚拟地址0x00000000到0xBFFFFFFF）

### 进程切换过程
1. 保存处理机上下文，包括程序计数器和其他寄存器。
2. 更新PCB信息。
3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
4. 选择另一个进程执行，并更新其PCB。
5. 更新内存管理的数据结构。
6. 恢复处理机上下文。

### 引起上下文切换的原因
* 时间片用完，CPU正常调度下一个任务
* 被其他优先级更高的任务抢占
* 执行任务碰到IO阻塞，调度器挂起当前任务，切换执行下一个任务
* 用户代码主动挂起当前任务让出CPU时间
* 多任务抢占资源，由于没有抢到被挂起
* 硬件中断

## 进程同步方式
### 临界区
对临界资源进行访问的那段代码称为临界区。
为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

``` 
        // entry section
        // critical section;
        // exit section
``` 

### 同步与互斥
同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。

互斥：多个进程在同一时刻只有一个进程能进入临界区。
### 信号量
信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；

up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。
``` 
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
``` 
#### 使用信号量实现生产者-消费者问题 
问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。
注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。
``` 
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
``` 
### 管程
使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。
``` 
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
``` 
管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。
## 进程通信方式
主要分为：管道、系统IPC（包括消息队列、信号量、共享存储）、SOCKET
### 管道
#### 匿名管道
管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。
``` 
#include <unistd.h>
int pipe(int fd[2]);
``` 
它具有以下限制：
* 只支持半双工通信（单向交替传输）；
* 只能在父子进程或者兄弟进程中使用。
#### 命名管道
常用于客户-服务器应用程序中，用作汇聚点，在客户进程和服务器进程之间传递数据。
* 只支持半双工通信（单向交替传输）；
* 可以在无血缘关系的进程之间使用。
``` 
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
``` 
#### 流管道
* 支持全双工通信；
* 只能在父子进程或者兄弟进程中使用。

### 消息队列
消息队列用于同一台机器上的进程间通信，它和管道很相似，是一个在系统内核上用来保存消息的队列。它在系统内核上以消息链表的形式出现。

相比于管道，消息队列具有以下优点：
* 消息队列可以独立于读写进程存在，从而避免了同步管道的打开和关闭时可能产生的困难；
* 避免了管道的同步阻塞问题，不需要进程自己提供同步方法；
* 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。
### 共享存储
允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

### 信号量
它是一个计数器，用于为多个进程提供对共享数据对象的访问，解决共享存储的同步问题。

### 套接字
与其它通信机制不同的是，它可用于不同机器间的进程通信。

## 进程调度算法
### 批处理系统
批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。
#### 先来先服务 first-come first-serverd（FCFS）
非抢占式的调度算法，按照请求的顺序进行调度。
有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。
#### 短作业优先 shortest job first（SJF）
非抢占式的调度算法，按估计运行时间最短的顺序进行调度。
长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。
#### 最短剩余时间优先 shortest remaining time next（SRTN）
最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。
### 交互式系统
交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。
#### 时间片轮转
将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。
时间片轮转算法的效率和时间片的大小有很大关系：
因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
而如果时间片过长，那么实时性就不能得到保证。
#### 优先级调度
为每个进程分配一个优先级，按优先级进行调度。
为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
#### 多级反馈队列
一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。
可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

### 父子进程
子进程完全复制了父进程的地址空间的内容，包括堆栈段和数据段的内容。但是子进程并没有复制代码段，而是和父进程共用代码段。这里的复制采用了写时复制的模式。只有当子进程修改这些数据内容的时候才开始复制。
### 僵尸进程
子进程退出后，父进程未退出且父进程尚未调用wait 函数来获取子进程的信息，那么子进程的进程描述符仍然保存在系统中，这种进程叫做僵尸进程。

### 孤儿进程
孤儿进程指的是父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将会被当前进程组的其他进程所收养 或者被init进程所收养。
### 守护进程
在Linux 或UNIX 操作系统中在系统的引导的时候会开启很多服务，这些服务叫做守护进程。这些进程脱离了终端并且在后台运行。它的生存期较长，通常独立于控制终端并且周期性的执行某种任务或等待某些事件的发生。

### 进程相关函数
#### Fork() 函数和 vfork 函数
Fork 函数创建一个新的进程，该子进程和父进程的状态几乎一样。二者共享相同的代码区，堆，栈，全局变量区等。它采用了写时拷贝（拷贝内存段，只有当真正需要修改内存的时候才会引发缺页中断，之后再拷贝过来）。这是为了避免exec函数在fork 之后执行造成的无用拷贝。

Vfork 函数的作用是在创建一个子进程后，该子进程会和父进程共享内存段，不需要进行拷贝,之后程序保证子进程先获得调度。这个时候直接调用exec.
#### Wait 和 waitpid
Waitpid 功能更加强大，可以等待特定的子进程。

#### Exec 函数
exec调用并没有生成新进程。一个进程一旦调用exec函数，它本身就“死亡”了，系统把代码段替换成新的程序的代码，废弃了原有的数据段和堆栈段，并为新程序分配新的数据段与堆栈段，惟一保留的就是进程ID。对系统而言，还是同一个进程，不过执行的是另一个程序了。

## 多线程
### 线程可见性
一个线程对共享变量值的修改，能够及时被其他线程里看到。
需要满足的条件是：
线程一将工作内存中的共享变量的改变更新到主内存中；
将主内存的更新的共享变量更新到线程二的工作内存中。
### 多线程应用场景
需要频繁的创建和销毁的就可以用多线程；
处理IO密集型这类耗时但不耗CPU的操作的时候，可以使用多线程。因为IO堵塞导致频繁切换；
多核分布的用线程，多机分布的用进程；
线程死掉等于包含线程的进程死掉，进程更安全些；
### 多线程同步
同步指的是在一定情况下只允许某个线程访问某个资源，而在此时间内，不允许其他线程访问该资源。可以通过互斥锁、条件变量、读写锁、信号量来同步资源。
#### 互斥锁
互斥锁意味着当一个线程锁定临界区之后，其他的线程将无法访问临界区，只能等待该线程将临界区解锁之后才能访问临界区。
#### 条件变量
当线程在等待某个条件满足的时候处于休眠状态，只有当条件满足的时候，会唤醒该线程。

条件变量通过允许线程堵塞和等待另一个线程发送信号的方法来弥补互斥量的不足，通过条件变量，可以节省系统的资源。

#### 读写锁
读写锁适应于对数据结构的读操作多于写操作的场合。读锁叫做共享锁，写锁叫做独占锁。

两种策略：
* 强读者同步：读者具有更高的优先权，只要写者当前没有进行写操作，读者便拥有访问权限。
* 强写者同步: 将优先权交给写者。读者只有等到所有正在等待或者正在执行的写者完成之后才有访问权限。
#### 信号量
互斥量只允许一个线程进入临界区，而信号量允许多个线程进入临界区。

当有线程访问临界区的时候，值减一，当有线程离开临界区的时候，值加一。当值小于0的时候，不允许新加线程访问临界区，当新加线程大于0的时候，新加线程仍可以访问临界区。

### 原子操作
#### 原子操作的内存顺序
* Relaxed松散顺序，这个就是说各个CPU读取的值是未定义的，一个CPU在一个线程中修改一个值后，其他CPU不了解。
* Sequentially-consistent 顺序一致顺序：只要原子操作中的值做了修改store，其他线程的load操作就会得到最新的值。程序中的行为从任意角度来看，序列顺序保持一致。
* Acquire_release顺序：一个原子做了这个acquire操作，肯定是读的是这个原子最后一次release操作修改的值。换句话说，要是采用release的方式store一个值，那么其他CPU都会看到这一次的修改。
#### 处理器如何保证原子操作
单核：保证操作指令序列不被打断即可。简单的原子操作：INC, XCHG。复杂的原子操作：自旋锁。
多核：CAS，总线锁，缓存锁。
#### CAS
CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

JVM中的CAS操作是利用了处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止。
```
while(true) {
    intexpect = a;
    if(a.compareAndSet(expect, a +1)) {
         doSomeThing1();
        return; 
     }else{ 
         doSomeThing2(); 
     }
}
```
存在的三大问题及解决方案
* ABA问题

因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。

* 循环时间长开销大

自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第一，它可以延迟流水线执行指令，使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候因内存顺序冲突而引起CPU流水线被清空，从而提高CPU的执行效率。

* 只能保证一个共享变量的原子操作。

当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。还有一个巧取的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j＝a，合并一下ij＝2a，然后用CAS来操作ij＝2a，然后用CAS来操作ij。从JDK1.5开始提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。

#### 总线锁
处理器提供一个lock信号，当一个处理器在总线上输出此信号，其他处理器的请求将被阻塞。总线锁把CPU和内存之间的通信锁住了，锁定期间，其他处理器不能操作其他内存地址的数据，开销较大。
#### 缓存锁
在同一时刻，保证对某个内存地址的操作原子性即可。频繁使用的内存先缓存在处理起的高速缓存里，原子操作可以直接在处理器内部缓存中进行。

如果共享内存如果被换存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性。缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。

处理器不会使用缓存锁定的情况：
* 当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行时，则处理器会调用总线锁定。
* 有些处理器不支持缓存锁定。对于Intel486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。
## 缓存
### 缓存IO
缓存 IO 又被称作标准 IO，大多数文件系统的默认 IO 操作都是缓存 IO。在 Linux 的缓存 IO 机制中，操作系统会将 IO 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

缓存 IO 的缺点：

数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。
### 缓存更新算法
FIFO
先进先出。最早存入的数据优先被淘汰。
LRU
最近最少使用。最近被使用时间最早的数据优先被淘汰。
```
//LRU Cache Algorithm
class LRUCache{
private:
	struct Node{
		int key;
		int value;
		Node(int k,int v):key(k),value(v){}
	};
	size_t maxCapacity; 
	list<Node> cacheList;
	unordered_map<int,list<Node>::iterator>cacheMap;

public:
	LRUCache(int maxCapacity):maxCapacity(maxCapacity){};
	int get(int key)
	{
        // There is no node with key(key) in CacheList
		if(cacheMap.find(key)==cacheMap.end())
		{
			return -1;
		}
        // There is a node with key(key) in CacheList, move it to CacheList head and return it's value
		cacheList.splice(cacheList.begin(),cacheList,cacheMap[key]);
		cacheMap[key]=cacheList.begin();
		return cacheMap[key]->value;
	}
	void set(int key,int value)
	{
        // There is no node with key(key) in CacheList
        // First check if the capacity reaches the max limit and remove the CacheList tail if needed
        // Then insert the new node into CacheList head
		if(cacheMap.find(key)==cacheMap.end())
		{
			if(cacheList.size()==maxCapacity)
			{
				cacheMap.erase(cacheList.back().key);
				cacheList.pop_back();
			}
			cacheList.push_front({key,value});
			cacheMap[key]=cacheList.begin();
		}
        // There is a node with key(key) in CacheList
        // Move the node to the CacheList head and update it's value
		else
		{
			cacheList.splice(cacheList.begin(),cacheList,cacheMap[key]);
			cacheMap[key]=cacheList.begin();
			cacheList.begin()->value=value;
		}
	}
};

```
LFU
最不经常使用。在一段时间内，数据呗使用次数最少的，优先被淘汰。
## 死锁
在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。
### 死锁产生的四个条件
* 互斥条件：一个资源一次只能被一个进程使用
* 请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放
* 不剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺
* 循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系 

### 预防死锁
* 资源一次性分配：（破坏请求和保持条件）
* 可剥夺资源：即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）
* 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）
### 避免死锁
预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。
### 检测死锁
首先为每个进程和每个资源指定一个唯一的号码；
然后建立资源分配表和进程等待表。
### 解除死锁
当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有：
* 剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；
* 撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。


## IO模型
### 概念
* 同步

一个任务的完成需要依赖另一个任务。只有被依赖的任务完成后，原任务才算完成。这是一种可靠的任务序列，两个任务的状态可以保持一致。
* 异步

不需要等待被依赖的任务完成，只是通知对方需要完成什么工作，然后继续做自己的工作。无法主动确定对方的任务最终是否真正完成，而只能等待别人通知。是不可靠的任务序列。
* 阻塞

调用结果返回之前，当前线程会被挂起，一直处于等待状态，不能执行其他任务。
* 非阻塞

调用结果返回之前，可以执行其他任务。

同步和异步的区别：原任务获取被调任务状态的方式，如果是主动查看消息状态，就是同步，如果是被动等待消息通知，就是异步。

阻塞和非阻塞的区别：在调用一个任务后，被调任务完成之前，原任务是否能够执行其他任务。

### 调用方式
* 同步阻塞：线程等待当前函数返回，在此期间不可执行其他消息处理。
* 同步非阻塞：线程等待当前函数返回，在此期间可以执行其他消息处理。
* 异步阻塞：线程被动等待消息通知，在此期间不可执行其他消息处理。
* 异步非阻塞：线程被动等待消息通知，在此期间可以执行其他消息处理。

### 网络 IO 过程
网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：

第一阶段：等待数据准备 (Waiting for the data to be ready)。

第二阶段：将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)。

对于socket流而言，

第一步：通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。

第二步：把数据从内核缓冲区复制到应用进程缓冲区。

### Linux IO 模型
#### 同步阻塞IO（synchronous bloking IO）
Linux 默认所有socket都是阻塞阻塞模型。

用户空间的应用程序执行一个系统调用（recvform），导致应用程序阻塞，直到数据到达应用程序缓冲区。
* 优点：能够及时返回数据，无延迟，操作简单。
* 缺点：IO 的两个阶段（收包存入内核缓冲区，从内核缓冲区复制到应用程序缓冲区）均处于等待状态，影响性能。
#### 同步非阻塞IO（non-blocking IO）
轮询（polling）：

非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。

但从内核缓冲区拷贝数据到应用程序缓冲区，这个阶段进程是阻塞的。

* 优点：能够利用起第一阶段的等待时间（等待接收数据并存入内核缓存区）执行其他任务。

* 缺点：任务完成的响应延迟增大（因为有轮询间隔），导致整体数据吞吐量降低。

#### 多路复用IO（multiplexing IO）
循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。UNIX/Linux 通过调用 select、poll、epoll 来实现。

进程可以调用select，等待多个socket，同时对多个IO端口进行监听，当其中任何一个socket数据准备好了，就能返回进行可读，再进行recvform调用，将数据从内核缓存区拷贝到应用程序缓存区。

通过把多个IO阻塞复用到同一个select的阻塞上，使得系统再单线程的情况下可以同时处理多个客户端请求，降低系统开销。

调用select，进入select阻塞，所以是同步模型。

#### 异步非阻塞IO（asynchronous IO）
用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。
等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。

IO两个阶段，进程都是非阻塞的。

### select poll epoll
#### select
采用轮询， 速度较慢，可以监控的文件描述符的数目是比较少的，但它的可移植性比较好。

#### poll
采用轮询，速度较慢，但是其可以监控的文件描述符的数目比较大，它的可移植性相对较差。
#### epoll 
支持的可监控的文件描述符比较大，且不采用轮询，而是通过注册+回调函数的方法，只会对活跃的socket 进行操作，因此速度较快。Epoll通过内存映射函数将内核与应用进程处于同一内存来实现，避免了不必要的内存拷贝。

Epoll 在Linux 下采用的是红黑树和双向链表来实现的。首先通过epoll_create系统调用在内核中创建eventpoll类型的句柄，其中包括红黑树 根节点和双向链表头结点，然后通过 epoll_ctl l往红黑树结构中添加删除修改时间，最后通过epoll_wait 函数来判断双向链表为空。如果为空则堵塞，当文件描述符状态改变，fd上的回调函数被调用，该函数将fd 加入到双向链表中，此时被唤醒，返回准备好的事件。

### epoll事件模型：
#### Level Triggered (LT) 水平触发
当检测到其上有事件发生并将事件通知应用程序后，应用程序可以不立即处理该事件，这样，当应用程序下一次调用的时候，仍然会向应用程序报告这个事件。
* socket接收缓冲区不为空 有数据可读 读事件一直触发
* socket发送缓冲区不满 可以继续写入数据 写事件一直触发

LT的处理过程：
* accept一个连接，添加到epoll中监听EPOLLIN事件
* 当EPOLLIN事件到达时，read fd中的数据并处理
* 当需要写出数据时，把数据write到fd中；如果数据较大，无法一次性写出，那么在epoll中监听EPOLLOUT事件
* 当EPOLLOUT事件到达时，继续把数据write到fd中；如果数据写出完毕，那么在epoll中关闭EPOLLOUT事件
#### Edge Triggered (ET) 边沿触发
当检测到事件发生并将此事件通知应用程序后，应用程序应立即处理这事件，在此之后，也将不再报告该事件。
* socket的接收缓冲区状态变化时触发读事件，即空的接收缓冲区刚接收到数据时触发读事件
* socket的发送缓冲区状态变化时触发写事件，即满的缓冲区刚空出空间时触发读事件

ET的处理过程：
* accept一个一个连接，添加到epoll中监听EPOLLIN|EPOLLOUT事件
* 当EPOLLIN事件到达时，read fd中的数据并处理，read需要一直读，直到返回EAGAIN为止
* 当需要写出数据时，把数据write到fd中，直到数据全部写完，或者write返回EAGAIN
* 当EPOLLOUT事件到达时，继续把数据write到fd中，直到数据全部写完，或者write返回EAGAIN

#### LT ET 对比
* ET的要求是需要一直读写，直到返回EAGAIN，否则就会遗漏事件。ET模式一定要设置为非堵塞的模式，如果文件描述符为堵塞，那么一定会在最后一次陷入堵塞状态。而LT的处理过程中，直到返回EAGAIN不是硬性要求，但通常的处理过程都会读写直到返回EAGAIN，但LT比ET多了一个开关EPOLLOUT事件的步骤。
* LT的编程与poll/select接近，符合一直以来的习惯，不易出错。
* ET的编程可以做到更加简洁，某些场景下更加高效，但另一方面容易遗漏事件，容易产生bug。

## 实时/非实时操作系统
* 实时操作系统

在外界事件或数据产生的时候，能够接受并以足够快的速度予以处理。

硬实时系统指的是必须在时间内完成操作，软实时则是按照事件的优先级，尽可能快的完成操作。

多任务、抢占调度、任务间的通信与同步、任务与中断的通信。
* 分时操作系统

完全按照时间片，让计算机与各终端用户的程序连接起来，轮流的切换给各终端用户使用。多路性，及时性，交互性，独立性。

实时性多用于过程控制。

流行的PC多用分时操作系统。

## 内存
### 虚拟内存
为了防止不同进程在同一个时刻在物理内存上运行时而对物理内存的争夺，采用了虚拟内存。

虚拟内存指的是在进程执行过程中，先将一部分从磁盘放到内存当中，当执行过程中，由操作系统负责将需要的磁盘调入，将不需要的信息从内存中调出。

虚拟内存的好处：
* 扩大寻址地址空间；
* 内存之间相互隔离，减少了内存之间的相互干扰；
* 有时候共享虚拟内存可以用来作为进程间通信的方式；
### 多级列表
使用多级列表可以使页表在内存中离散存储。不必寻求一整块大的内存空间。
### 缺页中断
在请求分页系统中，通过查询页表中的状态位来确定所有访问的页面是否在内存中，如果不在就会产生缺页中断。这个时候系统会根据页表的地址将其调入内存。

流程包括：保存现场，执行中断处理程序，恢复线程。

## 系统调用
为了调用创建文件、进程等操作系统所提供的服务。应用程序必须完成与操作系统进行交互。但是应用进程是不能直接访问操作系统的内核的。因此，操作系统可以通过软中断来引发一个异常，跳到system_call的内核位置，内核会检查系统调用号，找到该内核函数的入口地址，调用该函数，然后返回该进程。我们把这些返回的函数叫做系统调用，这些函数代表了用户空间到内核空间的一种转换。

