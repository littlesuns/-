# 操作系统
---
# 进程和线程
## 进程
进程是具有一定功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源调度和分配的一个独立单位。
进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。
## 线程
线程是进程的实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。
一个进程可以有多个线程，它们共享进程资源，多个线程也可以并发执行。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

## 进程和线程的区别
* 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
* 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
* 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
* 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

## 进程切换
### 用户空间 内核空间
对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2^32）。

操作系统将虚拟空间划分为两部分：
* 内核空间（Linux 最高的1G字节，从虚拟地址0xC0000000到0xFFFFFFFF）
* 用户空间（Linux 最低的3G字节，从虚拟地址0x00000000到0xBFFFFFFF）
### 进程切换过程
1. 保存处理机上下文，包括程序计数器和其他寄存器。
2. 更新PCB信息。
3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
4. 选择另一个进程执行，并更新其PCB。
5. 更新内存管理的数据结构。
6. 恢复处理机上下文。

### 引起上下文切换的原因
* 时间片用完，CPU正常调度下一个任务
* 被其他优先级更高的任务抢占
* 执行任务碰到IO阻塞，调度器挂起当前任务，切换执行下一个任务
* 用户代码主动挂起当前任务让出CPU时间
* 多任务抢占资源，由于没有抢到被挂起
* 硬件中断

## 线程同步方式

## 进程同步方式
### 临界区
对临界资源进行访问的那段代码称为临界区。
为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

``` 
        // entry section
        // critical section;
        // exit section
``` 

### 同步与互斥
同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。

互斥：多个进程在同一时刻只有一个进程能进入临界区。
### 信号量
信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；

up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。
``` 
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
``` 
#### 使用信号量实现生产者-消费者问题 
问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。
注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。
``` 
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
``` 
### 管程
使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。
``` 
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
``` 
管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。
## 进程通信方式
主要分为：管道、系统IPC（包括消息队列、信号量、共享存储）、SOCKET
### 管道
#### 匿名管道
管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。
``` 
#include <unistd.h>
int pipe(int fd[2]);
``` 
它具有以下限制：
* 只支持半双工通信（单向交替传输）；
* 只能在父子进程或者兄弟进程中使用。
#### 命名管道
常用于客户-服务器应用程序中，用作汇聚点，在客户进程和服务器进程之间传递数据。
* 只支持半双工通信（单向交替传输）；
* 可以在无血缘关系的进程之间使用。
``` 
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
``` 
#### 流管道
* 支持全双工通信；
* 只能在父子进程或者兄弟进程中使用。

### 消息队列
消息队列用于同一台机器上的进程间通信，它和管道很相似，是一个在系统内核上用来保存消息的队列。它在系统内核上以消息链表的形式出现。

相比于管道，消息队列具有以下优点：
* 消息队列可以独立于读写进程存在，从而避免了同步管道的打开和关闭时可能产生的困难；
* 避免了管道的同步阻塞问题，不需要进程自己提供同步方法；
* 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。
### 共享存储
允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

### 信号量
它是一个计数器，用于为多个进程提供对共享数据对象的访问，解决共享存储的同步问题。

### 套接字
与其它通信机制不同的是，它可用于不同机器间的进程通信。

## 进程调度算法
### 批处理系统
批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。
#### 先来先服务 first-come first-serverd（FCFS）
非抢占式的调度算法，按照请求的顺序进行调度。
有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。
#### 短作业优先 shortest job first（SJF）
非抢占式的调度算法，按估计运行时间最短的顺序进行调度。
长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。
#### 最短剩余时间优先 shortest remaining time next（SRTN）
最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。
### 交互式系统
交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。
#### 时间片轮转
将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。
时间片轮转算法的效率和时间片的大小有很大关系：
因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
而如果时间片过长，那么实时性就不能得到保证。
#### 优先级调度
为每个进程分配一个优先级，按优先级进行调度。
为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
#### 多级反馈队列
一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。
可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

### 父子进程
子进程完全复制了父进程的地址空间的内容，包括堆栈段和数据段的内容。但是子进程并没有复制代码段，而是和父进程共用代码段。这里的复制采用了写时复制的模式。只有当子进程修改这些数据内容的时候才开始复制。
### 僵尸进程
子进程退出后，父进程未退出且父进程尚未调用wait 函数来获取子进程的信息，那么子进程的进程描述符仍然保存在系统中，这种进程叫做僵尸进程。

### 孤儿进程
孤儿进程指的是父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将会被当前进程组的其他进程所收养 或者被init进程所收养。
### 守护进程
在Linux 或UNIX 操作系统中在系统的引导的时候会开启很多服务，这些服务叫做守护进程。这些进程脱离了终端并且在后台运行。它的生存期较长，通常独立于控制终端并且周期性的执行某种任务或等待某些事件的发生。

### 进程相关函数
#### Fork() 函数和 vfork 函数
Fork 函数创建一个新的进程，该子进程和父进程的状态几乎一样。二者共享相同的代码区，堆，栈，全局变量区等。它采用了写时拷贝（拷贝内存段，只有当真正需要修改内存的时候才会引发缺页中断，之后再拷贝过来）。这是为了避免exec函数在fork 之后执行造成的无用拷贝。

Vfork 函数的作用是在创建一个子进程后，该子进程会和父进程共享内存段，不需要进行拷贝,之后程序保证子进程先获得调度。这个时候直接调用exec.
#### Wait 和 waitpid
Waitpid 功能更加强大，可以等待特定的子进程。

#### Exec 函数
exec调用并没有生成新进程。一个进程一旦调用exec函数，它本身就“死亡”了，系统把代码段替换成新的程序的代码，废弃了原有的数据段和堆栈段，并为新程序分配新的数据段与堆栈段，惟一保留的就是进程ID。对系统而言，还是同一个进程，不过执行的是另一个程序了。


## 缓存
### 缓存IO
缓存 IO 又被称作标准 IO，大多数文件系统的默认 IO 操作都是缓存 IO。在 Linux 的缓存 IO 机制中，操作系统会将 IO 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

缓存 IO 的缺点：

数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。
### 缓存更新算法
FIFO
先进先出。最早存入的数据优先被淘汰。
LRU
最近最少使用。最近被使用时间最早的数据优先被淘汰。
```
//LRU Cache Algorithm
class LRUCache{
private:
	struct Node{
		int key;
		int value;
		Node(int k,int v):key(k),value(v){}
	};
	size_t maxCapacity; 
	list<Node> cacheList;
	unordered_map<int,list<Node>::iterator>cacheMap;

public:
	LRUCache(int maxCapacity):maxCapacity(maxCapacity){};
	int get(int key)
	{
        // There is no node with key(key) in CacheList
		if(cacheMap.find(key)==cacheMap.end())
		{
			return -1;
		}
        // There is a node with key(key) in CacheList, move it to CacheList head and return it's value
		cacheList.splice(cacheList.begin(),cacheList,cacheMap[key]);
		cacheMap[key]=cacheList.begin();
		return cacheMap[key]->value;
	}
	void set(int key,int value)
	{
        // There is no node with key(key) in CacheList
        // First check if the capacity reaches the max limit and remove the CacheList tail if needed
        // Then insert the new node into CacheList head
		if(cacheMap.find(key)==cacheMap.end())
		{
			if(cacheList.size()==maxCapacity)
			{
				cacheMap.erase(cacheList.back().key);
				cacheList.pop_back();
			}
			cacheList.push_front({key,value});
			cacheMap[key]=cacheList.begin();
		}
        // There is a node with key(key) in CacheList
        // Move the node to the CacheList head and update it's value
		else
		{
			cacheList.splice(cacheList.begin(),cacheList,cacheMap[key]);
			cacheMap[key]=cacheList.begin();
			cacheList.begin()->value=value;
		}
	}
};

```
LFU
最不经常使用。在一段时间内，数据呗使用次数最少的，优先被淘汰。
## 死锁
在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。
### 死锁产生的四个条件
* 互斥条件：一个资源一次只能被一个进程使用
* 请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放
* 不剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺
* 循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系 

### 预防死锁
* 资源一次性分配：（破坏请求和保持条件）
* 可剥夺资源：即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）
* 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）
### 避免死锁
预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。
### 检测死锁
首先为每个进程和每个资源指定一个唯一的号码；
然后建立资源分配表和进程等待表。
### 解除死锁
当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有：
* 剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；
* 撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。


## IO模型
### 概念
* 同步

一个任务的完成需要依赖另一个任务。只有被依赖的任务完成后，原任务才算完成。这是一种可靠的任务序列，两个任务的状态可以保持一致。
* 异步

不需要等待被依赖的任务完成，只是通知对方需要完成什么工作，然后继续做自己的工作。无法主动确定对方的任务最终是否真正完成，而只能等待别人通知。是不可靠的任务序列。
* 阻塞

调用结果返回之前，当前线程会被挂起，一直处于等待状态，不能执行其他任务。
* 非阻塞

调用结果返回之前，可以执行其他任务。

同步和异步的区别：原任务获取被调任务状态的方式，如果是主动查看消息状态，就是同步，如果是被动等待消息通知，就是异步。

阻塞和非阻塞的区别：在调用一个任务后，被调任务完成之前，原任务是否能够执行其他任务。

### 调用方式
* 同步阻塞：线程等待当前函数返回，在此期间不可执行其他消息处理。
* 同步非阻塞：线程等待当前函数返回，在此期间可以执行其他消息处理。
* 异步阻塞：线程被动等待消息通知，在此期间不可执行其他消息处理。
* 异步非阻塞：线程被动等待消息通知，在此期间可以执行其他消息处理。

### 网络 IO 过程
网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：

第一阶段：等待数据准备 (Waiting for the data to be ready)。

第二阶段：将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)。

对于socket流而言，

第一步：通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。

第二步：把数据从内核缓冲区复制到应用进程缓冲区。

### Linux IO 模型
#### 同步阻塞IO（synchronous bloking IO）
Linux 默认所有socket都是阻塞阻塞模型。

用户空间的应用程序执行一个系统调用（recvform），导致应用程序阻塞，直到数据到达应用程序缓冲区。
* 优点：能够及时返回数据，无延迟，操作简单。
* 缺点：IO 的两个阶段（收包存入内核缓冲区，从内核缓冲区复制到应用程序缓冲区）均处于等待状态，影响性能。
#### 同步非阻塞IO（non-blocking IO）
轮询（polling）：

非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。

但从内核缓冲区拷贝数据到应用程序缓冲区，这个阶段进程是阻塞的。

* 优点：能够利用起第一阶段的等待时间（等待接收数据并存入内核缓存区）执行其他任务。

* 缺点：任务完成的响应延迟增大（因为有轮询间隔），导致整体数据吞吐量降低。

#### 多路复用IO（multiplexing IO）
循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。UNIX/Linux 通过调用 select、poll、epoll 来实现。

进程可以调用select，等待多个socket，同时对多个IO端口进行监听，当其中任何一个socket数据准备好了，就能返回进行可读，再进行recvform调用，将数据从内核缓存区拷贝到应用程序缓存区。

通过把多个IO阻塞复用到同一个select的阻塞上，使得系统再单线程的情况下可以同时处理多个客户端请求，降低系统开销。

调用select，进入select阻塞，所以是同步模型。

#### 异步非阻塞IO（asynchronous IO）
用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。
等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。

IO两个阶段，进程都是非阻塞的。

## 实时/非实时操作系统
* 实时操作系统

在外界事件或数据产生的时候，能够接受并以足够快的速度予以处理。

硬实时系统指的是必须在时间内完成操作，软实时则是按照事件的优先级，尽可能快的完成操作。

多任务、抢占调度、任务间的通信与同步、任务与中断的通信。
* 分时操作系统

完全按照时间片，让计算机与各终端用户的程序连接起来，轮流的切换给各终端用户使用。多路性，及时性，交互性，独立性。

实时性多用于过程控制。

流行的PC多用分时操作系统。

## 内存
### 虚拟内存
为了防止不同进程在同一个时刻在物理内存上运行时而对物理内存的争夺，采用了虚拟内存。

虚拟内存指的是在进程执行过程中，先将一部分从磁盘放到内存当中，当执行过程中，由操作系统负责将需要的磁盘调入，将不需要的信息从内存中调出。

虚拟内存的好处：
* 扩大寻址地址空间；
* 内存之间相互隔离，减少了内存之间的相互干扰；
* 有时候共享虚拟内存可以用来作为进程间通信的方式；
### 多级列表
使用多级列表可以使页表在内存中离散存储。不必寻求一整块大的内存空间。
### 缺页中断
在请求分页系统中，通过查询页表中的状态位来确定所有访问的页面是否在内存中，如果不在就会产生缺页中断。这个时候系统会根据页表的地址将其调入内存。

流程包括：保存现场，执行中断处理程序，恢复线程。


