# 计算机网络
---
## 1.网络分层
* 应用层：应用进程间的交互，完成特定网络应用，DNS,HTTP,HTTPS,FTP（数据的传输协议）
* 表示层：数据压缩，加密
* 会话层：建立，管理和弘治表示层与实体之间的通信会话（自动连接，自动网络寻址）
* 传输层：向两台主机中进程之间的通信提供数据传输服务,TCP,UDP（端口与端口的通信）
* 网络层：选择最佳路由传输路径，主机间的逻辑通信（计算机连接路径）
* 链路层：将网络层的数据包封装成帧，使用链路层协议在相邻节点间的链路上传输，保证两（路由）节点之间可靠的数据传输（规定0 1的分包形式）
* 物理层：相邻计算机节点之间比特流的透明传输，屏蔽传输介质和物理设备，（把数据转换成0 1）
## 2.TCP UDP 的区别
* TCP是面向连接的，UDP是无连接的；
* TCP是可靠的，UDP是不可靠的；
* TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多的通信模式；
* TCP是面向字节流的，UDP是面向报文的；
* TCP有拥塞控制机制，UDP没有拥塞控制，适合媒体通信；
* TCP首部开销(20个字节)比UDP的首部开销(8个字节)要大；
## 3.UDP 如何构建 TCP 的能力
在应用层模拟TCP的确认应答，超时重传，流量控制等功能。

可以首先给其数据包编号，发送数据包后，接收端需要对数据包序列进行应答，如果没有收到需求特定的数据包的时候，让其重传数据。

## 4.TCP三次握手 四次挥手
### 三次握手
三次握手(我要和你建立链接，你真的要和我建立链接么，我真的要和你建立链接，成功)
* 第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。
* 第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。
* 第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。
### 四次挥手
我要和你断开链接；好的，断吧。我也要和你断开链接；好的，断吧
* 第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。
* 第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。此时TCP链接处于半关闭状态，即客户端已经没有要发送的数据了，但服务端若发送数据，则客户端仍要接收。
* 第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。
* 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。
### 为什么要三次握手
为了防止已失效的链接请求报文突然又传送到了服务端，因而产生错误。

客户端发出的连接请求报文并未丢失，而是在某个网络节点长时间滞留了，以致延误到链接释放以后的某个时间才到达Server。这是，Server误以为这是Client发出的一个新的链接请求，于是就向客户端发送确认数据包，同意建立链接。若不采用“三次握手”，那么只要Server发出确认数据包，新的链接就建立了。由于client此时并未发出建立链接的请求，所以其不会理睬Server的确认，也不与Server通信；而这时Server一直在等待Client的请求，这样Server就白白浪费了一定的资源。若采用“三次握手”，在这种情况下，由于Server端没有收到来自客户端的确认，则就会知道Client并没有要求建立请求，就不会建立链接。
### 为什么要四次挥手
TCP连接是双向传输的对等的模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接时，会发送指令告知对方，我要关闭连接了。这时对方会回一个ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，等到发送完了所有的数据后，会发送一个FIN段来关闭此方向上的连接。接收方发送ACK确认关闭连接。注意，接收到FIN报文的一方只能回复一个ACK, 它是无法马上返回对方一个FIN报文段的，因为结束数据传输的“指令”是上层应用层给出的，我只是一个“搬运工”，我无法了解“上层的意志”。
### SYN Flood
同时发送大量TCP连接请求。

问题出在TCP连接的三次握手中，假设一个用户向服务器发送了SYN报文后突然死机或掉线，那么服务器在发出SYN+ACK应答报文后是无法收到客户端的ACK报文的（第三次握手无法完成），这种情况下服务器端一般会重试（再次发送SYN+ACK给客户端）并等待一段时间后丢弃这个未完成的连接，这段时间的长度我们称为SYN Timeout，一般来说这个时间是分钟的数量级（大约为30秒-2分钟）。

一个用户出现异常导致服务器的一个线程等待1分钟并不是什么很大的问题，但如果有一个恶意的攻击者大量模拟这种情况，服务器端将为了维护一个非常大的半连接列表而消耗非常多的资源----数以万计的半连接，即使是简单的保存并遍历也会消耗非常多的CPU时间和内存，何况还要不断对这个列表中的IP进行SYN+ACK的重试。

解决方案：
* 在TCP中添加一个IP地址的cookie，通过对这个标记，如果收到大量来自于一个IP的连接的话，就拒绝该IP的连接。
* 减少SYN+time等待时间。

### time_wait
#### time_wait出现在哪一阶段 哪一端
客户端收到服务器的关闭连接请求时，客户端进入time_wait状态
#### MSL
报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。
#### 等待2MSL的原因
保证TCP协议的全双工连接能够可靠关闭保证这次连接的重复数据段从网络中消失。

* 第一点：如果主机1直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致主机2没有收到主机1最后回复的ACK。那么主机2就会在超时之后继续发送FIN，此时由于主机1已经CLOSED了，就找不到与重发的FIN对应的连接。所以，主机1不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。
* 第二点：如果主机1直接CLOSED，然后又再向主机2发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达主机2，由于新连接和老连接的端口号是一样的，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。
#### time_wait过多
TIME_WAIT 是主动关闭链接时形成的，等待2MSL时间，约4分钟。主要是防止最后一个ACK丢失。

由于TIME_WAIT的时间会非常长，因此server端应尽量减少主动关闭连接。

CLOSE_WAIT是被动关闭连接是形成的。根据TCP状态机，服务器端收到客户端发送的FIN，则按照TCP实现发送ACK，因此进入CLOSE_WAIT状态。

但如果服务器端不执行close()，就不能由CLOSE_WAIT迁移到LAST_ACK，则系统中会存在很多CLOSE_WAIT状态的连接。此时，可能是系统忙于处理读、写操作，而未将已收到FIN的连接，进行close。此时，recv/read已收到FIN的连接socket，会返回0。

如果服务器出了异常，百分之八九十都是下面两种情况：
* 服务器保持了大量TIME_WAIT状态
* 服务器保持了大量CLOSE_WAIT状态，简单来说CLOSE_WAIT数目过大是由于被动关闭连接处理不当导致的。

因为linux分配给一个用户的文件句柄是有限的，而TIME_WAIT和CLOSE_WAIT两种状态如果一直被保持，那么意味着对应数目的通道就一直被占着，而且是“占着茅坑不使劲”，一旦达到句柄数上限，新的请求就无法被处理了，接着就是大量Too Many Open Files异常，Tomcat崩溃。

#### 平静时间概念
如果处于2MSL等待事件内的主机发生故障，如果在MSL时间内重启的话，并立刻使用故障前的端口来发送连接请求的话，那么故障前从这个端口发送出的而迟到的报文段会被错误的认为是重启后新发送的报文段。这个时候便设置了TCP在重启动的MSL秒内不允许建立任何连接。

### accept
出现在三次握手之后。

流程：
* 服务器调用listen进行监听
* 客户端调用connect来发送syn报文
* 服务器协议栈负责三次握手的交互过程。链接建立后，往listen队列中添加一个成功的连接，直到队列达到最大长度。
* 服务器调用accept从listen队列中取出一条成功的TCP连接，并在listen队列中删除该连接。

## 5.TCP 可靠传输
### 确认应答机制
TCP每次发送一组数据的时候，会首产生一个序列号，当接收端接收到数据后，会产生一个应答信号，只有接收到应答信号，发送端才会继续发送。

为了提升速度，采用了累计应答的方式，即允许客户端采用流水式的发送方式，当接收方接收到一组数据后，可以对这组数据的最后一个序列号进行应答，表明这组数据是有效地。
### 超时重传机制
超时重传机制主要指的是当客户端没有接收到服务器端的应答，客户端重新发送数据包。
* 服务器端没有接受到客户端的数据，这个时候通过超时重传将数据重新发送给服务器。
* 服务器端接收到数据应答发送给客户端的过程失效了，在这种情况下，客户端会重新发送数据给服务器端，服务器端对这些重复的数据进行去重。如果服务器端的应答信号延迟接收了，客户端会受到两个应答信号，客户端对第二个应答信号不做响应。
### 流量控制
流量控制主要是根据接收方的处理能力来调节发送方的发送能力，防止发送方太快，接收方的缓冲区会满而导致丢包。

接收方可以通过将自己可以接收的缓冲区大小放到首部的窗口大小发送给发送端。如果发现自己缓冲区快满了就缩小窗口大小，如果缓冲区充足就增大窗口大小。

TCP的传输效率主要通过Nagle算法来保证。首先 TCP会将发送端的缓冲区的第一个字节发送出去。在此之后如果收到当前数据的应答，便发送剩下缓冲区中的数组组装成报文发送出去。或者是当发送缓冲区的数据已经达到发送窗口大小的一半或者是最大数据报文段的时候，便立刻将其发送出去。

如果接收的缓冲区足以容纳一个最大的报文段或者说接受的缓冲区有一半是空闲的时候。立刻向发送端发送确认信号。
### 拥塞控制
* 慢启动：先发送少量数据，测试下当前网络的拥塞状况。之后每隔轮次窗口大小变为原来的两倍。
* 拥塞避免：当达到一定阈值的时候，窗口大小开始呈现线性增加。
* 快重传：当接收方接收到一个失序的报文的时候，立刻发送报文，要求发送方立刻重传，发送发如果一连收到三个确认信号，即立刻重传。
* 快恢复是指它的门限值减半，调节窗口大小，执行拥塞避免算法。

## 6.TCP 拥塞控制
* 慢启动：从小到大逐渐增加拥塞窗口的大小（2的指数增长）
* 拥塞避免：让拥塞窗口缓慢增长（线性增长）
* 快重传：接收方在收到一个失序的报文段后立即发出重复确认，发送方只要一连收到3个重复确认就立即重传对方未收到的报文段
* 快恢复：发送方一连收到3个重复确认，就执行乘法减小算法，把门限减半，但不执行慢开始算法
## 7.TCP 流量控制
* 目的：防止分组丢失，实现TCP可靠传输。如果发送端发送数据太快，接收端来不及接收，就会丢包。为了避免丢包，就要控制发送端的发送速度。
* 方法：滑动窗口协议。保证了分组无差错，有序接收，流量控制。

接收方每一次返回的ACK包中都会包含自己当前接收窗口的大小，让发送发发送不超过这个大小的数据包。
* 问题：流量控制产生的死锁。发送端收到一个窗口为0的ACK，就停止发送数据，等待接收端把窗口增大。如果接收端窗口大于0的ACK在传输过程中丢失，发送端就会一直等待，接收端以为发送端收到了新的包，也会一直等待新数据的到来，双方相互等待，产生死锁。
* 解决死锁：持续计时器。当发送端收到一个0窗口的ACK，就启动持续计时器，计时器到了就主动发报文询问接收端新的窗口大小是多少。
## 8.保活计时器
如果传输双方不主动关闭连接，即使已经没有数据交换，还会一直占用资源。
保活计时器用于双方停止交互一段时间后，服务端主动探测客户端的状态。
当服务器发送探测报文时，客户端可能处于4种不同的情况：仍然正常运行、已经崩溃、已经崩溃并重启了、由于中间链路问题不可达。在不同的情况下，服务器会得到不一样的反馈。
* 客户主机依然正常运行，并且从服务器端可达

客户端的TCP响应正常，从而服务器端知道对方是正常的。保活定时器会在两小时以后继续触发。
* 客户主机已经崩溃，并且关闭或者正在重新启动

客户端的TCP没有响应，服务器没有收到对探测包的响应，此后每隔75s发送探测报文，一共发送9次。
socket函数会返回-1，errno设置为ETIMEDOUT，表示连接超时。
* 客户主机已经崩溃，并且重新启动了

客户端的TCP发送RST，服务器端收到后关闭此连接。
socket函数会返回-1，errno设置为ECONNRESET，表示连接被对端复位了。
* 客户主机依然正常运行，但是从服务器不可达

双方的反应和第二种是一样的，因为服务器不能区分对端异常与中间链路异常。
socket函数会返回-1，errno设置为EHOSTUNREACH，表示对端不可达。

## 9.TCP 粘包 拆包
### 粘包
* 发送方：发送端将多个间隔较小，数据量小的包融合成一个包发送。
* 接收方：不及时处理缓冲区的包，造成一次性取到了多个数据。

这个特别适合数据要求可靠传输，但是不需要太频繁传输的场合
### 拆包
* 数据包的长度超过了最大报文段，需要拆成多段发送
* 要发送的数据包大于发送缓冲区的剩余空间的大小，需要拆成多段接收
### 解决方法
* 发送端给每个数据添加首部，首部中记录包含数据包的长度
* 发送固定大小的数据包，不足补0
* 在数据包之间加特殊符号

## 10.TCP Nagle 算法 CORK 算法
### SWS 糊涂窗口综合症
SWS:Silly Window Syndrome 糊涂窗口综合症

当发送端应用进程产生数据很慢(telnet)、或接收端应用进程处理接收缓冲区数据很慢，或二者兼而有之；就会使应用进程间传送的报文段很小，特别是有效载荷很小。极端情况下，有效载荷可能只有1个字节；而传输开销有40字节(20字节的IP头+20字节的TCP头) 这种现象就叫糊涂窗口综合症。
### Nagle 算法
一个TCP连接上最多只能有一个未被确认的未完成的小分组，在该小分组的确认到达之前不允许发送其他的小分组，将没有发送的小分组全部缓存下来组成一个大的分组等到满足条件之后再发送。小分组指的是TCP报文长度小于MSS的任何分组。 目的是减少广域网的拥塞。 

Nagle算法的规则(可参考tcp_output.c文件里tcp_nagle_check函数注释)：
* 如果包长度达到MSS,则允许发送；
* 如果该包含有FIN,则允许发送；
* 设置了TCP_NODELAY选项,则允许发送；
* 未设置TCP_CORK选项时,若所有发出去的小数据包(包长度小于MSS)均被确认,则允许发送；
* 上述条件都未满足,但发生了超时(一般为200ms),则立即发送。

缺点：延迟确认增加了等待时间，有可能迫使发送端重传其未被确认的报文段。
### CORK 算法
* 发送端：TCP不关注是否有收到ACK报文, 只要当前缓存中累积的数据量不足以组成一个MTU大小的数据包就不会将数据包发出, 直到一个RTO超时后才会把不满足一个MTU大小的数据包发出去。
* 接收端：只要有数据到达就发送确认，但宣布的窗口大小为零，直到或者缓存空间已能放入具有最大长度的报文段，或者缓存空间的一半已经空了。

Nagle算法主要关心网络拥塞问题, 而CORK算法是为了提高网络的利用率. 但是两者都是为了尽量避免糊涂窗口综合症的问题。
### 延迟确认
当一个报文段到达时并不立即发送确认。接收端在确认收到的报文段之前一直等待，直到缓存有足够的空间为止。
#### 优点
* 延迟的确认防止了发送端的TCP滑动其窗口。当发送端的TCP发送完其数据后，它就停下来了。
* 它减少了通信量。接收端不需要确认每一个报文段。
#### 缺点
迟延的确认有可能迫使发送端重传其未被确认的报文段。可以用协议来平衡这个优点和缺点，例如现在定义了确认的延迟不能超过500毫秒。

## 11.HTTP 长连接 短链接
* 长连接

在一个TCP连接上可以连续发送多个数据包。
在TCP连接保持期间，如果没有数据包发送，需要双方定时发送数据包，以维持此连接。在HTTP1.1.中，默认的是长连接。
* 短连接
双方有数据交互的时候，就建立一个TCP连接，数据发送完成后就断开此连接。在HTTP/1.0中，默认的是短连接。

## HTTP
### HTTP
### HTTP HTTPS 的区别
* HTTP 的 URL 以 http:// 开头，而 HTTPS 的URL 以 https:// 开头
* HTTP 是不安全的，而 HTTPS 是安全的
* HTTP 标准端口是80，而 HTTPS 的标准端口是443
* 在OSI 网络模型中，HTTP工作于应用层，而HTTPS 的安全传输机制工作在传输层
* HTTP 无法加密，而HTTPS 对传输的数据进行加密
* HTTP无需证书，而HTTPS 需要CA机构wosign的颁发的SSL证书
### 常用的HTTP方法
* GET： 用于请求访问已经被URI（统一资源标识符）识别的资源，可以通过URL传参给服务器
* POST：用于传输信息给服务器，主要功能与GET方法类似，但一般推荐使用POST方式。
* PUT： 传输文件，报文主体中包含文件内容，保存到对应URI位置。
* HEAD： 获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效。
* DELETE：删除文件，与PUT方法相反，删除对应URI位置的文件。
* OPTIONS：查询相应URI支持的HTTP方法。
### HTTP 请求报文与响应报文格式
#### 请求报文
* 请求行：包含请求方法、URI、HTTP版本信息
* 请求首部字段
* 请求内容实体
* 空行
#### 响应报文
* 状态行：包含HTTP版本、状态码、状态码的原因短语
* 响应首部字段
* 响应内容实体
* 空行
### HTTP 常见首部
#### 通用首部字段（请求报文与响应报文都会使用的首部字段）
* Date：创建报文时间
* Connection：连接的管理
* Cache-Control：缓存的控制
* Transfer-Encoding：报文主体的传输编码方式

#### 请求首部字段（请求报文会使用的首部字段）
* Host：请求资源所在服务器
* Accept：可处理的媒体类型
* Accept-Charset：可接收的字符集
* Accept-Encoding：可接受的内容编码
* Accept-Language：可接受的自然语言

#### 响应首部字段（响应报文会使用的首部字段）
* Accept-Ranges：可接受的字节范围
* Location：令客户端重新定向到的URI
* Server：HTTP服务器的安装信息

#### 实体首部字段（请求报文与响应报文的的实体部分使用的首部字段）
* Allow：资源可支持的HTTP方法
* Content-Type：实体主类的类型
* Content-Encoding：实体主体适用的编码方式
* Content-Language：实体主体的自然语言
* Content-Length：实体主体的的字节数
* Content-Range：实体主体的位置范围，一般用于发出部分请求时使用
### 常见的HTTP状态码
#### 1XX 通知
#### 2XX 成功
* 200：请求被正常处理。
* 201：请求已创建。请求成功并且服务器创建了新的资源。
* 202：请求已接受。服务器已接受请求，但尚未处理。
* 203：非授权信息。服务器已成功处理了请求，但返回的信息可能来自另一来源。
* 204：请求被受理但没有资源可以返回。
* 206：客户端只是请求资源的一部分，服务器只对请求的部分资源执行GET方法，相应报文中通过Content-Range指定范围的资源。
#### 3XX 重定向
* 301：永久性重定向。
* 302：临时重定向。
* 303：与302状态码有相似功能，只是它希望客户端在请求一个URI的时候，能通过GET方法重定向到另一个URI。
* 304：发送附带条件的请求时，条件不满足时返回，与重定向无关。
* 307：临时重定向，与302类似，只是强制要求使用POST方法。
#### 4XX 客户端错误
* 400：请求报文语法有误，服务器无法识别。
* 401：请求需要认证。
* 403：请求的对应资源禁止被访问。
* 404：服务器无法找到对应资源。
#### 5XX 服务端错误
* 500：服务器内部错误。
* 503：服务器正忙。

### HTTP 无状态协议
无状态协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，也就是说，当客户端一次HTTP请求完成以后，客户端再发送一次HTTP请求，HTTP并不知道当前客户端是一个“老用户”。

可以使用Cookie来解决无状态的问题，Cookie就相当于一个通行证，第一次访问的时候给客户端发送一个Cookie，当客户端再次来的时候，拿着Cookie(通行证)，那么服务器就知道这个是“老用户”。
### cookie session 的区别
#### Cookie 
* cookie机制：服务器在本地机器上存储的小段文本并随每一个请求发送至同一个服务器。
* cookie生成：网络服务器用HTTP头向客户端发送cookies，在客户终端，浏览器解析这些cookies并将它们保存为一个本地文件，它会自动将同一服务器的任何请求缚上这些cookies 。纯粹的客户端脚本如JavaScript也可以生成cookie。
* cookie使用：浏览器检查所有存储的cookie，如果某个cookie所声明的作用范围大于等于将要请求的资源所在的位置，则把该cookie附在请求资源的HTTP请求头上发送给服务器。

#### Session
* session机制：服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。高效，安全，不依赖客户端环境。

当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了一个session标识（称为session id），如果已包含，服务器就按照session id把这个session检索出来使用，否则会新建一个。如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。
session生成之后会同时生成一个sessionID,该ID会发送到客户端的cookie 上，客户端通过发送该SessionID来找到服务器端的session。

#### 区别

* 存储位置不同

cookie存储在客户端。session存储在服务端。
* 存取方式不同

Cookie中只能保管ASCII字符串，假如需求存取Unicode字符或者二进制数据，需求先进行编码。Cookie中也不能直接存取Java对象。若要存储略微复杂的信息，运用Cookie是比拟艰难的。而Session中能够存取任何类型的数据，包括而不限于String、Integer、List、Map等。Session中也能够直接保管Java Bean乃至任何Java类，对象等，运用起来十分便当。能够把Session看做是一个Java容器类。

* 隐私策略的不同

Cookie存储在客户端阅读器中，对客户端是可见的，客户端的一些程序可能会窥探、复制以至修正Cookie中的内容。而Session存储在服务器上，对客户端是透明的，不存在敏感信息泄露的风险。假如选用Cookie，比较好的方法是，敏感的信息如账号密码等尽量不要写到Cookie中。最好是像Google、Baidu那样将Cookie信息加密，提交到服务器后再进行解密，保证Cookie中的信息只要本人能读得懂。而假如选择Session就省事多了，反正是放在服务器上，Session里任何隐私都能够有效的保护。

* 有效期上的不同

Cookie有效期很长。由于Session依赖于名为JSESSIONID的Cookie，而Cookie JSESSIONID的过期时间默许为–1，只需关闭了阅读器该Session就会失效，因而Session不能完成信息永世有效的效果。运用URL地址重写也不能完成。而且假如设置Session的超时时间过长，服务器累计的Session就会越多，越容易招致内存溢出。

* 服务器压力的不同

Session是保管在服务器端的，每个用户都会产生一个Session。假如并发访问的用户十分多，会产生十分多的Session，耗费大量的内存。因而像Google、Baidu、Sina这样并发访问量极高的网站，是不太可能运用Session来追踪客户会话的。而Cookie保管在客户端，不占用服务器资源。假如并发阅读的用户十分多，Cookie是很好的选择。关于Google、Baidu、Sina来说，Cookie或许是唯一的选择。

* 浏览器支持的不同

Cookie是需要客户端浏览器支持的。假如客户端禁用了Cookie，或者不支持Cookie，则会话跟踪会失效。关于WAP上的应用，常规的Cookie就派不上用场了。假如客户端浏览器不支持Cookie，需要运用Session以及URL地址重写。需要注意的是一切的用到Session程序的URL都要进行URL地址重写，否则Session会话跟踪还会失效。关于WAP应用来说，Session+URL地址重写或许是它唯一的选择。假如客户端支持Cookie，则Cookie既能够设为本浏览器窗口以及子窗口内有效（把过期时间设为–1），也能够设为一切阅读器窗口内有效（把过期时间设为某个大于0的整数）。但Session只能在本阅读器窗口以及其子窗口内有效。假如两个浏览器窗口互不相干，它们将运用两个不同的Session。（IE8下不同窗口Session相干）

* 跨域支持上的不同

Cookie支持跨域名访问，例如将domain属性设置为“.biaodianfu.com”，则以“.biaodianfu.com”为后缀的一切域名均能够访问该Cookie。跨域名Cookie如今被普遍用在网络中，例如Google、Baidu、Sina等。而Session则不会支持跨域名访问。Session仅在他所在的域名内有效。

### HTTP 优化方案
* TCP复用

TCP连接复用是将多个客户端的HTTP请求复用到一个服务器端TCP连接上，而HTTP复用则是一个客户端的多个HTTP请求通过一个TCP连接进行处理。前者是负载均衡设备的独特功能；而后者是HTTP 1.1协议所支持的新功能，目前被大多数浏览器所支持。
* 内容缓存

将经常用到的内容进行缓存起来，那么客户端就可以直接在内存中获取相应的数据了。
* 压缩

将文本数据进行压缩，减少带宽
* SSL加速（SSL Acceleration）

使用SSL协议对HTTP协议进行加密，在通道内加密并加速
* TCP缓冲

通过采用TCP缓冲技术，可以提高服务器端响应时间和处理效率，减少由于通信链路问题给服务器造成的连接负担。

### HTTP1.1 版本新特性
* 默认持久连接节省通信量，只要客户端服务端任意一端没有明确提出断开TCP连接，就一直保持连接，可以发送多次HTTP请求。
* 管线化，客户端可以同时发出多个HTTP请求，而不用一个个等待响应。
* 断点续传。实际上就是利用HTTP消息头使用分块传输编码，将实体主体分块传输。

### HTTPS 工作原理
1. 首先HTTP请求服务端生成证书，客户端对证书的有效期、合法性、域名是否与请求的域名一致、证书的公钥（RSA加密）等进行校验；
2. 客户端如果校验通过后，就根据证书的公钥的有效， 生成随机数，随机数使用公钥进行加密（RSA加密）；
3. 消息体产生的后，对它的摘要进行MD5（或者SHA1）算法加密，此时就得到了RSA签名；
4. 发送给服务端，此时只有服务端（RSA私钥）能解密。
5. 解密得到的随机数，再用AES加密，作为密钥（此时的密钥只有客户端和服务端知道）。
## 浏览器输入域名后的步骤
## 子网掩码 私有地址
## get post 的区别
## 网站攻击
## 攻击防范
## CRC算法
## 一致性哈希
